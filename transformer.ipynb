{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "13yKHkD1scQ44h9iaSTuIR4tbONnbzYlA",
      "authorship_tag": "ABX9TyNzLqxsm0b1Eo5JTbYdBiMB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsjfans/networks/blob/main/transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOkLvp_W39_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465a93b0-164e-4869-d9b5-4f3f303eb284"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Colab Notebooks',\n",
              " 'database',\n",
              " '职业个人资料.gslides',\n",
              " 'Untitled0.ipynb',\n",
              " 'transformer',\n",
              " 'transformer.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-8VC3TcNzA0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsye5HGv5ZqO"
      },
      "source": [
        "path += '/transformer'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFE9gU-z2V27"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmEx2NK74FgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0bc8f8-49f9-4836-e7ca-11bab7a056e2"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Niah3xAD2sRJ"
      },
      "source": [
        "## Constant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ4OvvFA2siE"
      },
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "PAD_WORD = '<blank>'\n",
        "UNK_WORD = '<unk>'\n",
        "BOS_WORD = '<s>'\n",
        "EOS_WORD = '</s>'\n",
        "PAD_TOKEN = 0\n",
        "UNK_TOKEN = 1\n",
        "BOS_TOKEN = 2\n",
        "EOS_TOKEN = 3\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "def get_pad_mask(seq, pad_idx):\n",
        "    return (seq != pad_idx).unsqueeze(-2)\n",
        "\n",
        "\n",
        "def get_subsequent_mask(seq):\n",
        "    ''' For masking out the subsequent info. '''\n",
        "    sz_b, len_s = seq.size()\n",
        "    subsequent_mask = (1 - torch.triu(\n",
        "        torch.ones((1, len_s, len_s), device=seq.device), diagonal=1)).bool()\n",
        "    return subsequent_mask\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4x4Ck-k6sha"
      },
      "source": [
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djYynGRy2gJM"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-pypAPwnTB2"
      },
      "source": [
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    ''' Scaled Dot-Product Attention '''\n",
        "\n",
        "    def __init__(self, temperature, attn_dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.dropout = nn.Dropout(attn_dropout)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "\n",
        "        attn = torch.matmul(q / self.temperature, k.transpose(2, 3))\n",
        "\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attn = self.dropout(F.softmax(attn, dim=-1))\n",
        "        output = torch.matmul(attn, v)\n",
        "\n",
        "        return output, attn\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    ''' Multi-Head Attention module '''\n",
        "\n",
        "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_head = n_head\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "\n",
        "        self.w_qs = nn.Linear(d_model, n_head * d_k, bias=False)\n",
        "        self.w_ks = nn.Linear(d_model, n_head * d_k, bias=False)\n",
        "        self.w_vs = nn.Linear(d_model, n_head * d_v, bias=False)\n",
        "        self.fc = nn.Linear(n_head * d_v, d_model, bias=False)\n",
        "\n",
        "        self.attention = ScaledDotProductAttention(temperature=d_k ** 0.5)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "\n",
        "        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n",
        "        sz_b, len_q, len_k, len_v = q.size(0), q.size(1), k.size(1), v.size(1)\n",
        "\n",
        "        residual = q\n",
        "\n",
        "        # Pass through the pre-attention projection: b x lq x (n*dv)\n",
        "        # Separate different heads: b x lq x n x dv\n",
        "        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n",
        "        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n",
        "        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n",
        "\n",
        "        # Transpose for attention dot product: b x n x lq x dv\n",
        "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)   # For head axis broadcasting.\n",
        "\n",
        "        q, attn = self.attention(q, k, v, mask=mask)\n",
        "\n",
        "        # Transpose to move the head dimension back: b x lq x n x dv\n",
        "        # Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)\n",
        "        q = q.transpose(1, 2).contiguous().view(sz_b, len_q, -1)\n",
        "        q = self.dropout(self.fc(q))\n",
        "        q += residual\n",
        "\n",
        "        q = self.layer_norm(q)\n",
        "\n",
        "        return q, attn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjmQ90dC2ovi"
      },
      "source": [
        "## Position "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFuwu0S92pND"
      },
      "source": [
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_hid, n_position=200):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # Not a parameter\n",
        "        self.register_buffer(\n",
        "            'pos_table', self._get_sinusoid_encoding_table(n_position, d_hid))\n",
        "\n",
        "    def _get_sinusoid_encoding_table(self, n_position, d_hid):\n",
        "        ''' Sinusoid position encoding table '''\n",
        "        # TODO: make it with torch instead of numpy\n",
        "\n",
        "        def get_position_angle_vec(position):\n",
        "            return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]\n",
        "\n",
        "        sinusoid_table = np.array([get_position_angle_vec(pos_i)\n",
        "                                   for pos_i in range(n_position)])\n",
        "        sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
        "        sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
        "\n",
        "        return torch.FloatTensor(sinusoid_table).unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pos_table[:, :x.size(1)].clone().detach()\n",
        "\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    ''' A two-feed-forward-layer module '''\n",
        "\n",
        "    def __init__(self, d_in, d_hid, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.w_1 = nn.Linear(d_in, d_hid)  # position-wise\n",
        "        self.w_2 = nn.Linear(d_hid, d_in)  # position-wise\n",
        "        self.layer_norm = nn.LayerNorm(d_in, eps=1e-6)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        residual = x\n",
        "\n",
        "        x = self.w_2(F.relu(self.w_1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x += residual\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYGj9bAK23sI"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDWpwFKO2a57"
      },
      "source": [
        "'''A wrapper class for scheduled optimizer '''\n",
        "\n",
        "\n",
        "class ScheduledOptim():\n",
        "    '''A simple wrapper class for learning rate scheduling'''\n",
        "\n",
        "    def __init__(self, optimizer, init_lr, d_model, n_warmup_steps):\n",
        "        self._optimizer = optimizer\n",
        "        self.init_lr = init_lr\n",
        "        self.d_model = d_model\n",
        "        self.n_warmup_steps = n_warmup_steps\n",
        "        self.n_steps = 0\n",
        "\n",
        "    def step_and_update_lr(self):\n",
        "        \"Step with the inner optimizer\"\n",
        "        self._update_learning_rate()\n",
        "        self._optimizer.step()\n",
        "\n",
        "    def zero_grad(self):\n",
        "        \"Zero out the gradients with the inner optimizer\"\n",
        "        self._optimizer.zero_grad()\n",
        "\n",
        "    def _get_lr_scale(self):\n",
        "        d_model = self.d_model\n",
        "        n_steps, n_warmup_steps = self.n_steps, self.n_warmup_steps\n",
        "        return (d_model ** -0.5) * min(n_steps ** (-0.5), n_steps * n_warmup_steps ** (-1.5))\n",
        "\n",
        "    def _update_learning_rate(self):\n",
        "        ''' Learning rate scheduling per step '''\n",
        "\n",
        "        self.n_steps += 1\n",
        "        lr = self.init_lr * self._get_lr_scale()\n",
        "\n",
        "        for param_group in self._optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV0HWPCP27Cc"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4vcNj7627N4"
      },
      "source": [
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    ''' Compose with two layers '''\n",
        "\n",
        "    def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.slf_attn = MultiHeadAttention(\n",
        "            n_head, d_model, d_k, d_v, dropout=dropout)\n",
        "        self.pos_ffn = PositionwiseFeedForward(\n",
        "            d_model, d_inner, dropout=dropout)\n",
        "\n",
        "    def forward(self, enc_input, slf_attn_mask=None):\n",
        "        enc_output, enc_slf_attn = self.slf_attn(\n",
        "            enc_input, enc_input, enc_input, mask=slf_attn_mask)\n",
        "        enc_output = self.pos_ffn(enc_output)\n",
        "        return enc_output, enc_slf_attn\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    ''' A encoder model with self attention mechanism. '''\n",
        "\n",
        "    def __init__(\n",
        "            self, n_src_vocab, d_word_vec, n_layers, n_head, d_k, d_v,\n",
        "            d_model, d_inner, pad_idx, dropout=0.1, n_position=200):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.src_word_emb = nn.Embedding(\n",
        "            n_src_vocab, d_word_vec, padding_idx=pad_idx)\n",
        "        self.position_enc = PositionalEncoding(\n",
        "            d_word_vec, n_position=n_position)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.layer_stack = nn.ModuleList([\n",
        "            EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout)\n",
        "            for _ in range(n_layers)])\n",
        "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "\n",
        "    def forward(self, src_seq, src_mask, return_attns=False):\n",
        "\n",
        "        enc_slf_attn_list = []\n",
        "\n",
        "        # -- Forward\n",
        "\n",
        "        enc_output = self.dropout(\n",
        "            self.position_enc(self.src_word_emb(src_seq)))\n",
        "        enc_output = self.layer_norm(enc_output)\n",
        "\n",
        "        for enc_layer in self.layer_stack:\n",
        "            enc_output, enc_slf_attn = enc_layer(\n",
        "                enc_output, slf_attn_mask=src_mask)\n",
        "            enc_slf_attn_list += [enc_slf_attn] if return_attns else []\n",
        "\n",
        "        if return_attns:\n",
        "            return enc_output, enc_slf_attn_list\n",
        "        return enc_output,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYYWC65A3Bxv"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttMV3Y8s3B9E"
      },
      "source": [
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    ''' Compose with three layers '''\n",
        "\n",
        "    def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.slf_attn = MultiHeadAttention(\n",
        "            n_head, d_model, d_k, d_v, dropout=dropout)\n",
        "        self.enc_attn = MultiHeadAttention(\n",
        "            n_head, d_model, d_k, d_v, dropout=dropout)\n",
        "        self.pos_ffn = PositionwiseFeedForward(\n",
        "            d_model, d_inner, dropout=dropout)\n",
        "\n",
        "    def forward(\n",
        "            self, dec_input, enc_output,\n",
        "            slf_attn_mask=None, dec_enc_attn_mask=None):\n",
        "        dec_output, dec_slf_attn = self.slf_attn(\n",
        "            dec_input, dec_input, dec_input, mask=slf_attn_mask)\n",
        "        dec_output, dec_enc_attn = self.enc_attn(\n",
        "            dec_output, enc_output, enc_output, mask=dec_enc_attn_mask)\n",
        "        dec_output = self.pos_ffn(dec_output)\n",
        "        return dec_output, dec_slf_attn, dec_enc_attn\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    ''' A decoder model with self attention mechanism. '''\n",
        "\n",
        "    def __init__(\n",
        "            self, n_trg_vocab, d_word_vec, n_layers, n_head, d_k, d_v,\n",
        "            d_model, d_inner, pad_idx, n_position=200, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.trg_word_emb = nn.Embedding(\n",
        "            n_trg_vocab, d_word_vec, padding_idx=pad_idx)\n",
        "        self.position_enc = PositionalEncoding(\n",
        "            d_word_vec, n_position=n_position)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.layer_stack = nn.ModuleList([\n",
        "            DecoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout)\n",
        "            for _ in range(n_layers)])\n",
        "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "\n",
        "    def forward(self, trg_seq, trg_mask, enc_output, src_mask, return_attns=False):\n",
        "\n",
        "        dec_slf_attn_list, dec_enc_attn_list = [], []\n",
        "\n",
        "        # -- Forward\n",
        "        dec_output = self.dropout(\n",
        "            self.position_enc(self.trg_word_emb(trg_seq)))\n",
        "        dec_output = self.layer_norm(dec_output)\n",
        "\n",
        "        for dec_layer in self.layer_stack:\n",
        "            dec_output, dec_slf_attn, dec_enc_attn = dec_layer(\n",
        "                dec_output, enc_output, slf_attn_mask=trg_mask, dec_enc_attn_mask=src_mask)\n",
        "            dec_slf_attn_list += [dec_slf_attn] if return_attns else []\n",
        "            dec_enc_attn_list += [dec_enc_attn] if return_attns else []\n",
        "\n",
        "        if return_attns:\n",
        "            return dec_output, dec_slf_attn_list, dec_enc_attn_list\n",
        "        return dec_output,\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDaWEqAo3L0-"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j6fNcQO3L9O"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    ''' A sequence to sequence model with attention mechanism. '''\n",
        "\n",
        "    def __init__(\n",
        "            self, n_src_vocab, n_trg_vocab, src_pad_idx, trg_pad_idx,\n",
        "            d_word_vec=512, d_model=512, d_inner=2048,\n",
        "            n_layers=6, n_head=8, d_k=64, d_v=64, dropout=0.1, n_position=200,\n",
        "            trg_emb_prj_weight_sharing=True, emb_src_trg_weight_sharing=True):\n",
        "\n",
        "        super().__init__()\n",
        "        self.src_pad_idx, self.trg_pad_idx = src_pad_idx, trg_pad_idx\n",
        "        self.encoder = Encoder(\n",
        "            n_src_vocab=n_src_vocab, n_position=n_position,\n",
        "            d_word_vec=d_word_vec, d_model=d_model, d_inner=d_inner,\n",
        "            n_layers=n_layers, n_head=n_head, d_k=d_k, d_v=d_v,\n",
        "            pad_idx=src_pad_idx, dropout=dropout)\n",
        "\n",
        "        self.decoder = Decoder(\n",
        "            n_trg_vocab=n_trg_vocab, n_position=n_position,\n",
        "            d_word_vec=d_word_vec, d_model=d_model, d_inner=d_inner,\n",
        "            n_layers=n_layers, n_head=n_head, d_k=d_k, d_v=d_v,\n",
        "            pad_idx=trg_pad_idx, dropout=dropout)\n",
        "\n",
        "        self.trg_word_prj = nn.Linear(d_model, n_trg_vocab, bias=False)\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "        assert d_model == d_word_vec, \\\n",
        "            'To facilitate the residual connections, \\\n",
        "         the dimensions of all module outputs shall be the same.'\n",
        "\n",
        "        self.x_logit_scale = 1.\n",
        "        if trg_emb_prj_weight_sharing:\n",
        "            # Share the weight between target word embedding & last dense layer\n",
        "            self.trg_word_prj.weight = self.decoder.trg_word_emb.weight\n",
        "            self.x_logit_scale = (d_model ** -0.5)\n",
        "\n",
        "        if emb_src_trg_weight_sharing:\n",
        "            self.encoder.src_word_emb.weight = self.decoder.trg_word_emb.weight\n",
        "\n",
        "    def forward(self, src_seq, trg_seq):\n",
        "\n",
        "        src_mask = get_pad_mask(src_seq, self.src_pad_idx)\n",
        "        trg_mask = get_pad_mask(\n",
        "            trg_seq, self.trg_pad_idx) & get_subsequent_mask(trg_seq)\n",
        "\n",
        "        enc_output, *_ = self.encoder(src_seq, src_mask)\n",
        "        dec_output, *_ = self.decoder(trg_seq, trg_mask, enc_output, src_mask)\n",
        "        seq_logit = self.trg_word_prj(dec_output) * self.x_logit_scale\n",
        "\n",
        "        return seq_logit.view(-1, seq_logit.size(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7T4tu8R3Pkt"
      },
      "source": [
        "## Translator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN1M3aBe9fIG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I45LgYyn3Ps1"
      },
      "source": [
        "\n",
        "class Translator(nn.Module):\n",
        "    ''' Load a trained model and translate in beam search fashion. '''\n",
        "\n",
        "    def __init__(\n",
        "            self, model, beam_size, max_seq_len,\n",
        "            src_pad_idx, trg_pad_idx, trg_bos_idx, trg_eos_idx):\n",
        "\n",
        "        super(Translator, self).__init__()\n",
        "\n",
        "        self.alpha = 0.7\n",
        "        self.beam_size = beam_size\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_bos_idx = trg_bos_idx\n",
        "        self.trg_eos_idx = trg_eos_idx\n",
        "\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "\n",
        "        self.register_buffer('init_seq', torch.LongTensor([[trg_bos_idx]]))\n",
        "        self.register_buffer(\n",
        "            'blank_seqs',\n",
        "            torch.full((beam_size, max_seq_len), trg_pad_idx, dtype=torch.long))\n",
        "        self.blank_seqs[:, 0] = self.trg_bos_idx\n",
        "        self.register_buffer(\n",
        "            'len_map',\n",
        "            torch.arange(1, max_seq_len + 1, dtype=torch.long).unsqueeze(0))\n",
        "\n",
        "    def _model_decode(self, trg_seq, enc_output, src_mask):\n",
        "        trg_mask = get_subsequent_mask(trg_seq)\n",
        "        dec_output, * \\\n",
        "            _ = self.model.decoder(trg_seq, trg_mask, enc_output, src_mask)\n",
        "        return F.softmax(self.model.trg_word_prj(dec_output), dim=-1)\n",
        "\n",
        "    def _get_init_state(self, src_seq, src_mask):\n",
        "        beam_size = self.beam_size\n",
        "\n",
        "        enc_output, *_ = self.model.encoder(src_seq, src_mask)\n",
        "        dec_output = self._model_decode(self.init_seq, enc_output, src_mask)\n",
        "\n",
        "        best_k_probs, best_k_idx = dec_output[:, -1, :].topk(beam_size)\n",
        "\n",
        "        scores = torch.log(best_k_probs).view(beam_size)\n",
        "        gen_seq = self.blank_seqs.clone().detach()\n",
        "        gen_seq[:, 1] = best_k_idx[0]\n",
        "        enc_output = enc_output.repeat(beam_size, 1, 1)\n",
        "        return enc_output, gen_seq, scores\n",
        "\n",
        "    def _get_the_best_score_and_idx(self, gen_seq, dec_output, scores, step):\n",
        "        assert len(scores.size()) == 1\n",
        "\n",
        "        beam_size = self.beam_size\n",
        "\n",
        "        # Get k candidates for each beam, k^2 candidates in total.\n",
        "        best_k2_probs, best_k2_idx = dec_output[:, -1, :].topk(beam_size)\n",
        "\n",
        "        # Include the previous scores.\n",
        "        scores = torch.log(best_k2_probs).view(\n",
        "            beam_size, -1) + scores.view(beam_size, 1)\n",
        "\n",
        "        # Get the best k candidates from k^2 candidates.\n",
        "        scores, best_k_idx_in_k2 = scores.view(-1).topk(beam_size)\n",
        "\n",
        "        # Get the corresponding positions of the best k candidiates.\n",
        "        best_k_r_idxs, best_k_c_idxs = best_k_idx_in_k2 // beam_size, best_k_idx_in_k2 % beam_size\n",
        "        best_k_idx = best_k2_idx[best_k_r_idxs, best_k_c_idxs]\n",
        "\n",
        "        # Copy the corresponding previous tokens.\n",
        "        gen_seq[:, :step] = gen_seq[best_k_r_idxs, :step]\n",
        "        # Set the best tokens in this beam search step\n",
        "        gen_seq[:, step] = best_k_idx\n",
        "\n",
        "        return gen_seq, scores\n",
        "\n",
        "    def translate_sentence(self, src_seq):\n",
        "        # Only accept batch size equals to 1 in this function.\n",
        "        assert src_seq.size(0) == 1\n",
        "\n",
        "        src_pad_idx, trg_eos_idx = self.src_pad_idx, self.trg_eos_idx\n",
        "        max_seq_len, beam_size, alpha = self.max_seq_len, self.beam_size, self.alpha\n",
        "\n",
        "        with torch.no_grad():\n",
        "            src_mask = get_pad_mask(src_seq, src_pad_idx)\n",
        "            enc_output, gen_seq, scores = self._get_init_state(\n",
        "                src_seq, src_mask)\n",
        "\n",
        "            ans_idx = 0   # default\n",
        "            for step in range(2, max_seq_len):    # decode up to max length\n",
        "                dec_output = self._model_decode(\n",
        "                    gen_seq[:, :step], enc_output, src_mask)\n",
        "                gen_seq, scores = self._get_the_best_score_and_idx(\n",
        "                    gen_seq, dec_output, scores, step)\n",
        "\n",
        "                # Check if all path finished\n",
        "                # -- locate the eos in the generated sequences\n",
        "                eos_locs = gen_seq == trg_eos_idx\n",
        "                # -- replace the eos with its position for the length penalty use\n",
        "                seq_lens, _ = self.len_map.masked_fill(\n",
        "                    ~eos_locs, max_seq_len).min(1)\n",
        "                # -- check if all beams contain eos\n",
        "                if (eos_locs.sum(1) > 0).sum(0).item() == beam_size:\n",
        "                    # TODO: Try different terminate conditions.\n",
        "                    _, ans_idx = scores.div(seq_lens.float() ** alpha).max(0)\n",
        "                    ans_idx = ans_idx.item()\n",
        "                    break\n",
        "        return gen_seq[ans_idx][:seq_lens[ans_idx]].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKtghvBq3jp7"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvrgVNhRBhRL"
      },
      "source": [
        "def dict2obj(info:dict):\n",
        "  t = type('new',(object,),info)\n",
        "  seqs = tuple, list, set, frozenset\n",
        "  for i, j in info.items():\n",
        "        if isinstance(j, dict):\n",
        "            setattr(t, i, dict2obj(j))\n",
        "        elif isinstance(j, seqs):\n",
        "            setattr(t, i,\n",
        "                type(j)(dict2obj(sj) if isinstance(sj, dict) else sj for sj in j))\n",
        "        else:\n",
        "            setattr(t, i, j)\n",
        "  return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm25OdgM-Xj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099392a2-7f4d-4408-d9e9-59635b34d32b"
      },
      "source": [
        "\n",
        "\n",
        "Opt = {\n",
        "    'train_src':f'{path}/data/train_en',\n",
        "    'train_tgt':f'{path}/data/train_cn',\n",
        "    'dev_src':f'{path}/data/valid_en',\n",
        "    'dev_tgt':f'{path}/data/valid_cn',\n",
        "    'n_src_vocab':None,\n",
        "    'n_tgt_vocab':None,\n",
        "    'min_word_count':1,\n",
        "    'max_len':50,\n",
        "    'save_data':f'{path}/back/data',\n",
        "    'd_model':512,\n",
        "    'train_path':f'{path}/back/data_train',\n",
        "    'n_warmup_steps':4000,\n",
        "    'min_word_count':1,\n",
        "    'max_len':50,\n",
        "    'save_model':f'{path}/model',\n",
        "    'n_head':8,\n",
        "    'n_layers':6,\n",
        "    'd_inner_hid':2048,\n",
        "    'd_k':64,\n",
        "    'd_v':64,\n",
        "    'epochs':20,\n",
        "    'batch_size':32,\n",
        "    'max_src_len':50,\n",
        "    'max_tgt_len':50,\n",
        "    'dropout':0.2,\n",
        "    'smoothing':0.1,\n",
        "    'epoch':0,\n",
        "    'checkpoint':None,\n",
        "    'device':device,\n",
        "    'd_word_vec':512,\n",
        "    'src_pad_idx':PAD_TOKEN,\n",
        "    'trg_pad_idx':PAD_TOKEN,\n",
        "}\n",
        "\n",
        "opt = dict2obj(Opt)\n",
        "opt.epoch\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss4HBGK5B_3a"
      },
      "source": [
        " \n",
        "info = torch.load(opt.train_path)\n",
        "src_dict, tgt_dict = info['src_dict'], info['tgt_dict']\n",
        "opt.n_src_vocab = len(src_dict)\n",
        "opt.n_tgt_vocab = len(tgt_dict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J74Klp9VC7w4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3efe184-c114-4803-a26b-2e0b7b538dce"
      },
      "source": [
        "opt.n_src_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbUqlDsE3ggq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96625479-0e4b-400d-f063-73687a730d74"
      },
      "source": [
        "'''\n",
        "This script handles the training process.\n",
        "'''\n",
        "import time\n",
        "from tqdm import tqdm \n",
        "import _thread\n",
        "\n",
        "\n",
        "def print_performances(header, loss, accu, start_time):\n",
        "    print('  - {header:12} ppl: {loss: 8.5f}, accuracy: {accu:3.3f} %, '\n",
        "          'elapse: {elapse:3.3f} min'.format(\n",
        "              header=f\"({header})\", loss=loss,\n",
        "              accu=100 * accu, elapse=(time.time() - start_time) / 60))\n",
        "\n",
        "\n",
        "def cal_performance(pred, gold, trg_pad_idx, smoothing=False):\n",
        "    ''' Apply label smoothing if needed '''\n",
        "\n",
        "    loss = cal_loss(pred, gold, trg_pad_idx, smoothing=smoothing)\n",
        "\n",
        "    pred = pred.max(1)[1]\n",
        "    gold = gold.contiguous().view(-1)\n",
        "    non_pad_mask = gold.ne(trg_pad_idx)\n",
        "    n_correct = pred.eq(gold).masked_select(non_pad_mask).sum().item()\n",
        "    n_word = non_pad_mask.sum().item()\n",
        "\n",
        "    return loss, n_correct, n_word\n",
        "\n",
        "\n",
        "def cal_loss(pred, gold, trg_pad_idx, smoothing=False):\n",
        "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
        "\n",
        "    gold = gold.contiguous().view(-1)\n",
        "\n",
        "    if smoothing:\n",
        "        eps = 0.1\n",
        "        n_class = pred.size(1)\n",
        "\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
        "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
        "        log_prb = F.log_softmax(pred, dim=1)\n",
        "\n",
        "        non_pad_mask = gold.ne(trg_pad_idx)\n",
        "        loss = -(one_hot * log_prb).sum(dim=1)\n",
        "        loss = loss.masked_select(non_pad_mask).sum()  # average later\n",
        "    else:\n",
        "        loss = F.cross_entropy(\n",
        "            pred, gold, ignore_index=trg_pad_idx, reduction='sum')\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_epoch(model, training_data, optimizer, trg_pad_idx, smoothing):\n",
        "    ''' Epoch operation in training phase'''\n",
        "\n",
        "    model.train()\n",
        "    total_loss, n_word_total, n_word_correct = 0, 0, 0\n",
        "    desc = '  - (Training)   '\n",
        "    for batch in tqdm(training_data, mininterval=2, desc=desc, leave=False):\n",
        "        # prepare data\n",
        "        enc_inputs, enc_inputs_len = batch.src\n",
        "        dec_, dec_inputs_len = batch.trg\n",
        "        dec_inputs = dec_[:, :-1]\n",
        "        dec_targets = dec_[:, 1:]\n",
        "        dec_inputs_len = dec_inputs_len - 1\n",
        "\n",
        "        # forward\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(enc_inputs, dec_inputs)\n",
        "\n",
        "        # backward and update parameters\n",
        "        loss, n_correct, n_word = cal_performance(\n",
        "            pred, dec_targets, trg_pad_idx, smoothing=smoothing)\n",
        "        loss.backward()\n",
        "        optimizer.step_and_update_lr()\n",
        "\n",
        "        # note keeping\n",
        "        n_word_total += n_word\n",
        "        n_word_correct += n_correct\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    loss_per_word = total_loss / n_word_total\n",
        "    accuracy = n_word_correct / n_word_total\n",
        "    return loss_per_word, accuracy\n",
        "\n",
        "\n",
        "def save_checkpoint(opt, model, epoch='least'):\n",
        "\n",
        "    checkpoint = {'settings': opt,  'model': model.state_dict(\n",
        "    ), 'epoch': (opt.epochs if epoch == 'least' else epoch) + 1}\n",
        "    model_name = f'./model/train_epoch_{epoch}.chkpt'\n",
        "    torch.save(checkpoint, model_name)\n",
        "\n",
        "\n",
        "def load_checkpoint(opt):\n",
        "    if opt.checkpoint is not None:\n",
        "        checkpoint = torch.load(opt.checkpoint)\n",
        "        opt = checkpoint['settings']\n",
        "        opt.epoch = checkpoint['epoch']\n",
        "        return opt\n",
        "    else:\n",
        "        return opt\n",
        "\n",
        "\n",
        "def train(model, training_data, optimizer, opt):\n",
        "    ''' Start training '''\n",
        "\n",
        "    all_loss = []\n",
        "    all_acc = []\n",
        "    if opt.epoch >= opt.epochs:\n",
        "        print('The start epoch more than epochs, stop training')\n",
        "        return\n",
        "    for epoch in range(opt.epoch, opt.epochs):\n",
        "        print('[ Epoch', epoch, ']')\n",
        "        start = time.time()\n",
        "        train_loss, train_accu = train_epoch(\n",
        "            model, training_data, optimizer, opt.trg_pad_idx, smoothing=opt.smoothing)\n",
        "        all_loss.append(train_loss)\n",
        "        all_acc.append(train_accu)\n",
        "        print_performances('Training', train_loss, train_accu, start)\n",
        "        thread.start_new_thread(save_checkpoint,(opt, model, epoch,))\n",
        "    thread.start_new_thread(save_checkpoint,(opt, model,))\n",
        "\n",
        "def make_model(opt):\n",
        "    transformer = Transformer(\n",
        "        opt.n_src_vocab,\n",
        "        opt.n_tgt_vocab,\n",
        "        src_pad_idx=opt.src_pad_idx,\n",
        "        trg_pad_idx=opt.trg_pad_idx,\n",
        "        d_k=opt.d_k,\n",
        "        d_v=opt.d_v,\n",
        "        d_model=opt.d_model,\n",
        "        d_word_vec=opt.d_word_vec,\n",
        "        d_inner=opt.d_inner_hid,\n",
        "        n_layers=opt.n_layers,\n",
        "        n_head=opt.n_head,\n",
        "        dropout=opt.dropout)\n",
        "\n",
        "    return transformer.to(opt.device)\n",
        "\n",
        "\n",
        "print(opt)\n",
        "_, _, training_data, _ = load_train_data(\n",
        "      opt.train_path, opt.batch_size, opt.max_src_len, opt.max_tgt_len, opt.device)\n",
        "transformer = make_model(opt)\n",
        "optimizer = ScheduledOptim(\n",
        "optim.Adam(transformer.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
        "        2.0, opt.d_model, opt.n_warmup_steps)\n",
        "train(transformer, training_data, optimizer, opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class '__main__.new'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 0/3123 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[ Epoch 0 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 1/3123 [00:09<8:34:54,  9.90s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 2/3123 [00:24<9:47:09, 11.29s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 3/3123 [00:39<10:51:44, 12.53s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 4/3123 [00:50<10:17:14, 11.87s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 5/3123 [01:00<9:56:10, 11.47s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 6/3123 [01:12<9:59:32, 11.54s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 7/3123 [01:23<9:58:48, 11.53s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 8/3123 [01:36<10:09:39, 11.74s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 9/3123 [01:45<9:36:15, 11.10s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 10/3123 [01:57<9:49:36, 11.36s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 11/3123 [02:09<9:57:52, 11.53s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 12/3123 [02:22<10:21:29, 11.99s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 13/3123 [02:35<10:28:01, 12.12s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 14/3123 [02:45<10:07:54, 11.73s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   0%|          | 15/3123 [02:58<10:12:50, 11.83s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 16/3123 [03:08<9:56:03, 11.51s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 17/3123 [03:23<10:40:11, 12.37s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 18/3123 [03:35<10:44:15, 12.45s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 19/3123 [03:46<10:09:31, 11.78s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 20/3123 [03:58<10:17:40, 11.94s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 21/3123 [04:10<10:14:18, 11.88s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 22/3123 [04:23<10:33:27, 12.26s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 23/3123 [04:36<10:46:58, 12.52s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 24/3123 [04:46<10:11:25, 11.84s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 25/3123 [04:59<10:21:01, 12.03s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 26/3123 [05:10<10:11:32, 11.85s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 27/3123 [05:23<10:24:02, 12.09s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 28/3123 [05:36<10:35:45, 12.32s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 29/3123 [05:46<10:06:39, 11.76s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 30/3123 [05:58<10:08:30, 11.80s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 31/3123 [06:10<10:06:02, 11.76s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 32/3123 [06:21<9:56:20, 11.58s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 33/3123 [06:35<10:32:24, 12.28s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 34/3123 [06:47<10:37:36, 12.38s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 35/3123 [06:59<10:34:14, 12.32s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 36/3123 [07:12<10:42:06, 12.48s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 37/3123 [07:23<10:15:50, 11.97s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 38/3123 [07:37<10:48:44, 12.62s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|          | 39/3123 [07:48<10:27:56, 12.22s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|▏         | 40/3123 [08:00<10:19:40, 12.06s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|▏         | 41/3123 [08:14<10:48:19, 12.62s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|▏         | 42/3123 [08:26<10:36:54, 12.40s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|▏         | 43/3123 [08:39<10:41:20, 12.49s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|▏         | 44/3123 [08:49<10:10:11, 11.89s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|▏         | 45/3123 [09:02<10:30:16, 12.29s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   1%|▏         | 46/3123 [09:14<10:18:27, 12.06s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 47/3123 [09:25<10:05:43, 11.82s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 48/3123 [09:37<10:02:35, 11.76s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 49/3123 [09:51<10:36:59, 12.43s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 50/3123 [10:03<10:28:04, 12.26s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 51/3123 [10:15<10:22:09, 12.15s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 52/3123 [10:27<10:30:28, 12.32s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 53/3123 [10:41<10:51:42, 12.74s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 54/3123 [10:54<10:49:52, 12.71s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 55/3123 [11:06<10:38:52, 12.49s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 56/3123 [11:18<10:34:58, 12.42s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 57/3123 [11:28<10:00:57, 11.76s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 58/3123 [11:42<10:26:48, 12.27s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 59/3123 [11:51<9:46:00, 11.48s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 60/3123 [12:04<10:05:11, 11.86s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 61/3123 [12:16<10:11:42, 11.99s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  - (Training)   :   2%|▏         | 62/3123 [12:26<9:44:44, 11.46s/it] \u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}